\chapter{Evaluation}
\label{cha:evaluation}
In this chapter, we evaluate the results of the thesis. The evaluation is separated into two parts. In the first part, we evaluate our simulation. This includes the how good the simulation is in terms of realism and problems it can simulate, the computational effort with the resulting simulation speed, the use and advantages of the simulation and the limitations we encountered. The second part shows the evaluation of the multi-robot system and our improvements with the simulation. Here we present the performance of different configurations with different agent improvements.

\section{Simulation}
\label{sec:simulation}
\subsection{Realism}
In this section, we show how realistic our simulation is, which problems we can simulate and which problems we can not simulate. Because there is no general measurement method to determine the realism of a robot simulator, we divide the problem and investigate all building block of the simulation. Afterwards, we also give a qualitative review how the simulation as a whole differs from reality.\\
Visually, our simulation can represent the basic structure of the LLSF environment. This already allows us to perform our vision tasks, which include brightness detection and color finding, in the simulation. However, it is difficult so simulate some problems that appear in reality. Especially reflections and ambient light can cause false positive vision detections we can not simulate. Physically, Gazebo is able to simulate a realistic interaction between objects, but it is difficult to find appropriate friction parameters for objects, what can result in weird physical behavior. Furthermore, we have to compose the physical representation of an object by simple geometries because complex geometries are computationally costly to simulate. This also can cause a difference between simulation and reality. We are able to simulate movement of the Robotino, collisions with objects and other robots and pushing pucks well. However, we simulate the movement of the Robotino and carrying pucks in a gripper on a higher abstraction level because of already mentioned problems with omni-directional wheels and pucks moving out of the gripper during turning. The distance sensors of the simulation produce realistic data because the data is easy to compute and we add Gaussian noise to the data. The only problem with the added noise in the current version is that the variance of the error added to a computed distance is constant whereas in reality the error depends on the distance. Therefore, in the simulation, the noise in the measured distance is higher as in reality for near objects. This seems to be no problem. We have not recognized a difference between the localization with amcl in the simulation and in reality. The gyroscope sensor also is easy to simulate and we have not recognized a difference to real sensor data. The communication between robots and the Refbox can also cause problems in reality. We simulate package loss which is the major cause for the problem. We do not simulate communication delay because this problem is not so important in the LLSF environment. In the simulation, the impact of communication problems on the multi-robot system is similar to what we have observed during the RoboCup 2013.\\
The simulation speed also can have an impact on the realism of the simulation. We minimized this impact by synchronizing the time of Fawkes and the Refbox with the simulation time. Because of the estimation method we use there to decrease the amount of sent Protobuf messages, a small time difference remains. We measured this difference 5 times. \textcolor{red}{append measurements?} Every time, the difference was less than 25 seconds for an 18 minutes game. Therefore, the impact on the performance is small.
Slower update rates of sensors and movement commands are useful to increase the speed of the simulation but can also cause differences between simulation and reality. We use update rates which are compromises between realism and computational speed. The update rate of the laser range finder is $5 Hz$, what is the half frequency of the real sensor, and there is no impact on the localization recognizable. The update rate of the webcam is $2 Hz$ and therefore much slower than in reality. This increases the delay of vision results and has no important impact on the performance of a robot because the plugin light\_front detects light states with a delay of about one second.\\
We compare the performance of our system at the RoboCup 2013 with the performance of the system with the same configuration in the simulation in section~\ref{sec:multi_robot_strategies}. The raw amount of points achieved in simulation and reality can not be used to evaluate the realism of the simulator because of different conditions. In the real competition, teams can take misbehaving robots out of the game and can restart a single robot once. We do not use this possibility in automated simulation runs. Furthermore, less vision failures which can have a large impact on the performance occur in the simulation. However, LLSF games in reality and our simulation look very similar because the robots perform the same actions and the problems that cause the robots to loose time or behave wrongly are the same or similar. For example the Movebase movement, which looks nervous and does much recovery behavior when facing obstacles, is the same in the simulation and the problem of interpreting a green light as a finished production, although the robot did not correctly place a puck under the machine, happens in the same way.
\textcolor{red}{pictures?}

\subsection{Computational Performance}
The computational performance is important for a good simulation. If the simulation is computationally costly and runs on a slow computer, the simulation speed drops significantly. The \textit{simulation speed} is the time interval that can be simulated per second. For example, if a simulation needs $10$ seconds to simulate what a robot does in $5$ seconds, the simulation speed would be $0.5$. In the following, the simulation speed also is called \textit{real-time factor}. The simulation speed is important for testing because testing with a low simulation speed requires more time. This is especially important for manual testing. There are possibilities to increase the simulation speed and to reduce the computational cost of the simulation. This can also be used to run the simulation with a speed greater than one and can therefore speed up the testing process even more. Gazebo provides three parameters for adjusting the simulation speed and detail. \textcolor{red}{link Gazebo SDF description?} First, it is possible to determine a \textit{target real-time factor} which limits how fast the simulation may run. It is only an upper limit and may not be reached if the computer is too slow. The default target real time-factor is $1$. Second, there is the \textit{maximal step-size} which determines the maximal time interval between two times a component of the simulation can do updates. Increasing the maximal step-size allows the simulation to run faster because the simulation simulates a larger time with one step. However, this can cause the simulation to be less accurate because simulation components have a higher response time. The default value of the maximal step-size is $0.001$. Third, there is the possibility to adjust the \textit{real-time update-rate} which determines the update calls of the  physical simulation per real-time second. By decreasing this parameter, the simulation becomes computationally less costly and the physical simulation of objects in the simulation becomes less detailed. This has an especially high impact on the simulation of collisions because collisions are detected later. The default value of the real-time update-rate is $1000$\\
We could increase the simulation speed significantly by tuning these three parameters. However, we experienced an impact on the quality of the simulation. With a real-time update-rate below $600$, we recognized unrealistic simulation of collisions between pucks and between robots. With a maximal step-size above $0.002$ and a resulting real time-factor above $1.5$, we recognized that the Robotino more often drives against obstacles. We think this is due to the higher distance the Robotino can travel between two update iterations of the Movebase. We think a maximal step size of $0.0015$, a real-time-factor of $1$ and a real-time update-rate of $750$ are a reasonable compromise between quality and speed of the simulation. \textcolor{red}{Include Figure simulation speed and CPU usage over time at different parameters}\\
There also is another important bottleneck. Often the computational power needed for the programs which control the robots in the simulation is so large that there is less CPU usage available for Gazebo. This is caused by the fact, that we operate multiple robot control programs on the same machine. The impact on the simulation speed is especially high if there are obstacles on the path of a robot and Movebase costly re-plans the path repeatedly. Therefore, the simulation highly depends on the number of simulated robots. \textcolor{red}{Figures composition of CPU usages with full simulation and only one simulated robot}. We reduced this problem by distributing the simulation and the robot control programs over multiple computers. This is especially easy to do with Movebase and helps us to avoid the major simulation speed drops when robots face obstacles.
The memory usage of the simulation is no real problems because most current computers can handle the memory requirements. \textcolor{red}{Figure Memory usage full simulation}

\subsection{Use for Multi-Robot System Development}
Expendability: hackathon
problem test specific situation
\subsection{Limitations}

\section{Multi-Robot Strategies}
\label{sec:multi_robot_strategies}
\subsection{Dynamic Role Change}
\subsection{Recycling}
digital optical distance sensor adjustment
\subsection{Role Configurations}
\subsection{Different Abstraction Levels}
bad network influence eval




realism: time error?

